<!DOCTYPE html>
<html lang="fa" dir="rtl">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>مدل‌های زبانی خود-سوال‌ساز - طاها باختری</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    <style>
        @font-face {
            font-family: 'DigiRastinPlus';
            src: url('../Digi-Rastin-Plus/Digi Rastin Plus Rectangle.ttf') format('truetype');
        }
        html { direction: rtl; }
        body { 
            font-family: 'DigiRastinPlus', 'Tahoma', Arial, sans-serif; 
            max-width: 800px; 
            margin: 0 auto; 
            padding: 40px 20px; 
            direction: rtl; 
            text-align: right;
            background: #ffffff;
            color: #333;
            line-height: 1.8;
        }
        * { direction: rtl; }
        .article-title { 
            font-size: 2.5rem; 
            color: #2c3e50; 
            text-align: center; 
            margin-bottom: 20px; 
            font-weight: 700;
        }
        .article-meta { 
            text-align: center; 
            color: #666; 
            margin-bottom: 40px; 
            display: flex;
            justify-content: center;
            gap: 20px;
            flex-wrap: wrap;
        }
        .article-content { 
            line-height: 1.8; 
            font-size: 1.1rem; 
            text-align: right;
        }
        .article-content h1, .article-content h2, .article-content h3 {
            color: #2c3e50;
            margin-top: 2rem;
            margin-bottom: 1rem;
        }
        .article-content p {
            margin-bottom: 1.5rem;
        }
        .article-tags {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #f0f0f0;
        }
        .tag {
            display: inline-block;
            background: #3498db;
            color: white;
            padding: 5px 12px;
            border-radius: 20px;
            font-size: 0.9rem;
            margin: 5px 5px 5px 0;
            text-decoration: none;
        }
    </style>
</head>
<body>
    <div style="text-align: center; margin-bottom: 40px; border-bottom: 2px solid #f0f0f0; padding-bottom: 30px;">
        <h1 class="article-title">مدل‌های زبانی خود-سوال‌ساز</h1>
        <div class="article-meta">
            <div><i class="fas fa-user"></i> طاها باختری</div>
            <div><i class="fas fa-calendar"></i> ۱۴۰۴/۵/۲۶</div>
        </div>
    </div>
    <div class="article-content"><p>یه مدل زبانی بزرگ (LLM) خودش رو فقط با یه موضوع اولیه آموزش می‌ده، بدون اینکه سوالی از انسان داشته باشه یا برچسبی بهش داده بشه.</p>

<p>این مدل هم نقش معلم رو داره و هم دانش‌آموز. خودش سوال می‌سازه و با یادگیری تقویتی یاد می‌گیره.</p>

<p>فقط کافیه به دو بخش تقسیم بشه: یکی که سوال‌ها رو می‌نویسه (پیشنهاددهنده) و یکی دیگه که بهشون جواب می‌ده (حل‌کننده). هر دو با یادگیری تقویتی بهتر می‌شن.</p>

<p>با داده‌هایی که خودش درست کرده، یه مدل با ۳ میلیارد پارامتر تونسته تو تست‌های جداگونه ۱۴ درصد تو حساب، ۱۶ درصد تو جبر و ۷ درصد تو کدنویسی پیشرفت کنه.<br></p>
<p>یه نکته باحال که باعث موفقیتش شده اینه: وقتی بررسی جواب‌ها سخته، از رای اکثریت چند تلاش حل‌کننده استفاده می‌کنه. اما وقتی بررسی آسونه، مثل کدنویسی، پیشنهاددهنده تست‌های واحد می‌سازه و حل‌کننده بر اساس درصد تست‌هایی که پاس می‌کنه، پاداش می‌گیره.</p>

<p>این روش باعث می‌شه سوال‌ها نه خیلی ساده باشن و نه خیلی سخت، و سطحشون خودکار با پیشرفت حل‌کننده تنظیم بشه.</p>

<h3>چرخه دوتایی</h3>
<p>آموزش بین پیشنهاددهنده و حل‌کننده به‌صورت یکی‌درمیون پیش می‌ره. هر کدوم پاداش خودشون رو بر اساس خروجی اون یکی به حداکثر می‌رسونن، یه جور ساختار ساده مینیمکس.</p>

<p>این کار باعث می‌شه برنامه درسی داده‌ها به توانایی فعلی مدل گره بخوره، و سختی سوال‌ها با پیشرفت حل‌کننده تنظیم بشه.</p>

<h3>مسائل با فاصله کم، رای اکثریت</h3>
<p>تو حوزه‌هایی مثل حساب که بررسی جواب به اندازه تولیدش سخته، حل‌کننده چند بار (مثلاً N بار) جواب می‌ده و جوابی که اکثریت داره به‌عنوان حقیقت موقت برای پاداش در نظر گرفته می‌شه.</p>

<p>پیشنهاددهنده فقط وقتی پاداش می‌گیره که سوالش نه خیلی آسون باشه و نه خیلی سخت، یعنی بعضی جواب‌ها با اکثریت جور دربیان، اما نه همه‌شون.</p>

<h3>مسائل با فاصله زیاد، تست‌های واحد</h3>
<p>تو کدنویسی، تأیید جواب با تست‌های واحد راحت‌تر از نوشتن راه‌حل کامله. برای همین پیشنهاددهنده تست‌ها رو می‌سازه و پاداش حل‌کننده بر اساس درصد تست‌هایی که پاس می‌کنه حساب می‌شه.</p>

<p>پیشنهاددهنده وقتی پاداش می‌گیره که حل‌کننده بعضی تست‌ها رو پاس کنه، ولی نه همه‌شون. این باعث می‌شه سوال‌های قابل‌حل اما چالش‌برانگیز تولید بشه.</p>

<h3>ساختار آموزش و داده‌ها</h3>
<p>همه‌چیز از یه موضوع ساده مثل «مسائل کلامی جبر» شروع می‌شه، بدون اینکه نمونه سوالی بهش داده بشه.</p>

<p>از مدل‌های پایه تنظیم‌شده کوچیک استفاده می‌کنن: Qwen2.5-3B-Instruct برای ریاضی و Qwen2.5-Coder-3B-Instruct برای کدنویسی، با نمونه‌گیری N=4 جواب برای هر سوال.</p>

<p>ارزیابی با ۴۰۹۶ مسئله ضرب سه‌رقمی، ۱۰۰ مسئله کلامی معادلات خطی از OMEGA و ۱۲۳ مسئله از Codeforces انجام شده.</p>

<h3>به‌روزرسانی پیشنهاددهنده</h3>
<p>به‌روزرسانی پیشنهاددهنده هر ۵ مرحله تعادل خوبی ایجاد می‌کنه، با امتیازهای قوی و نوسان کمتر نسبت به به‌روزرسانی هر مرحله یا اصلاً به‌روزرسانی نکردن.</p>

<p>اگه بیش از حد به‌روزرسانی کنن، پیشرفت حل‌کننده ناپایدار می‌شه، و اگه خیلی کم باشه، برنامه درسی گیر می‌کنه.</p>

<h3>تنوع و محافظ‌ها</h3>
<p>اگه ۶۴۰۰ مسئله رو یه‌دفعه تولید کنن، تنوع کم می‌شه و یادگیری ضربه می‌خوره. ولی تولید آنلاین با به‌روزرسانی‌های پیشنهاددهنده تنوع رو حفظ می‌کنه، همون‌طور که تو مقایسه‌ها و نمودارهای PCA دیده شده.</p>

<p>نویسنده‌ها به یه سری مهندسی‌های دستی اشاره کردن، مثل تکرار تو طراحی دستورات برای حفظ فرمت خروجی‌ها، و همین‌طور خطر خطاهای خود-تقویت‌شونده وقتی هیچ برچسب خارجی نیست.</p>

<h3>ایده به زبان ساده</h3>
<p>مدل یه چرخه بسته رو اجرا می‌کنه: پیشنهاددهنده از یه موضوع اولیه سوال می‌سازه و حل‌کننده سعی می‌کنه بهش جواب بده.</p>

<p>هر دو نقش رو یه مدل زبانی پایه بازی می‌کنه که با یادگیری تقویتی آموزش دیده. پس سیستم بدون نیاز به سوال یا جواب انسانی خودش رو راه می‌ندازه.</p>

<h3>چرا این روش کار می‌کنه؟</h3>
<p>راز موفقیتش تو برنامه درسیه که از تعامل به وجود می‌آد، نه یه مجموعه داده ثابت.</p>

<p>برنامه درسی یعنی ترتیب سوال‌هایی که مدل می‌بینه، با سطح سختی که با مهارت فعلی مدل تنظیم می‌شه. به این روش می‌گن خود-سوال‌سازی، جایی که مدل پایه هم پیشنهاددهنده‌ست و هم حل‌کننده، و با یادگیری تقویتی کار می‌کنه. این‌جوری داده‌ها بر اساس عملکرد مدل شکل می‌گیرن، نه یه مجموعه داده آماده.</p>

<p>پاداش‌ها کم اما هوشمندانه‌ان: پیشنهاددهنده دنبال سوال‌های جذاب و قابل‌حله، و حل‌کننده دنبال جواب‌های پایدار یا قابل‌تأییده.</p>

<p>این چرخه هزینه کمی داره و آزمایش و تکرارش رو آسون می‌کنه.</p>

<h3>نتیجه نهایی</h3>
<p>برنامه درسی به‌خاطر این شکل می‌گیره که پیشنهاددهنده فقط برای سوال‌های قابل‌حل اما نه خیلی ساده پاداش می‌گیره، و حل‌کننده فقط برای جواب‌های پایدار یا قابل‌تأیید. این دوتا مدام همدیگه رو به سمت یه نقطه بهینه می‌کشن، جایی که یادگیری سریع‌تر اتفاق می‌افته.</p></div>
    
    <a href="../index.html" style="display: inline-flex; align-items: center; gap: 8px; margin-top: 30px; padding: 12px 20px; background: #3498db; color: white; text-decoration: none; border-radius: 25px; font-weight: 500;"><i class="fas fa-arrow-right"></i> بازگشت به صفحه اصلی</a>
</body>
</html>